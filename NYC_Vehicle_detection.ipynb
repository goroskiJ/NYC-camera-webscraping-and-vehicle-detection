{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622f78cf-6c49-4eee-9e9b-b26442bbb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93747bff-f2ed-4a4c-b5d2-fde2ae41ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c8660f-11fa-4bec-9246-35fb273981ed",
   "metadata": {},
   "source": [
    "The URL is from NYC DOT Real-Time \n",
    "Traffic Information which allows access to the public to ~900 CCTV cameras of New York City Roads. This code Is only scraps to images provided from one camera that being from camera WBB SIR -2 @ Manhattan Mid Span that is west facing. The end goal of this project is to observe more bridge and/ or tunnel cameras to see the volume of traffic going in and out of different boroughs to see what areas are most populated at what hour. To achieve this goal the script will need to run at different times of the day and week to see the difference by workday. potentially be used during different times of the year to see if there are any seasonal changes.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead708a8-eb66-46fc-ae24-11de4de315d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the webpage containing the image\n",
    "url = \"https://webcams.nyctmc.org/api/cameras/368290bb-cebf-4845-8644-92382dcccd96/image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf613283-0170-46e3-bf0d-e8c0f862ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save location of the images as jp's\n",
    "output_directory = os.path.expanduser(\"~/Desktop/NYC_pic_test/Manhattan_Mid_Span_West_facing/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f8ae70-ff84-4fef-b60f-fb040fe0a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1f6733-05d9-4e68-9e87-292610691c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as Images\\captured_image_1712065961.jpg\n",
      "Image saved as Images\\captured_image_1712065963.jpg\n",
      "Image saved as Images\\captured_image_1712065965.jpg\n",
      "Image saved as Images\\captured_image_1712065967.jpg\n",
      "Image saved as Images\\captured_image_1712065969.jpg\n",
      "Image saved as Images\\captured_image_1712065970.jpg\n",
      "Image saved as Images\\captured_image_1712065972.jpg\n",
      "Image saved as Images\\captured_image_1712065974.jpg\n",
      "Image saved as Images\\captured_image_1712065976.jpg\n",
      "Image saved as Images\\captured_image_1712065978.jpg\n",
      "Image saved as Images\\captured_image_1712065980.jpg\n",
      "Image saved as Images\\captured_image_1712065982.jpg\n",
      "Image saved as Images\\captured_image_1712065984.jpg\n",
      "Image saved as Images\\captured_image_1712065986.jpg\n",
      "Image saved as Images\\captured_image_1712065987.jpg\n",
      "Image saved as Images\\captured_image_1712065989.jpg\n",
      "Program terminated by user.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            # Fetch the image data\n",
    "            response = requests.get(url)\n",
    "            image_data = response.content\n",
    "    \n",
    "            # Save the image data to a file\n",
    "            image_filename = os.path.join(output_directory, f\"captured_image_{int(time.time())}.jpg\")\n",
    "            with open(image_filename, \"wb\") as f:\n",
    "                f.write(image_data)\n",
    "    \n",
    "            s = image_filename\n",
    "            # Find the last occurrence of '/'\n",
    "            last_slash_index = s.rfind('/')\n",
    "            \n",
    "            # Slice the string to get everything after the last '/'\n",
    "            result = s[last_slash_index+1:]\n",
    "            location = s[ :last_slash_index]\n",
    "            \n",
    "            print(f\"Image saved as {result}\")\n",
    "    \n",
    "            #print(f\"Image located at {location}\")\n",
    "    \n",
    "            # Wait for 1 seconds before capturing the next image\n",
    "            time.sleep(1)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            # Handle any exceptions (e.g., network issues)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Program terminated by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94352031-fe00-45fd-b1d8-d825a5a5dbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as my_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory containing your JPG files\n",
    "image_folder = 'C:/Users/Jared Goroski/Desktop/NYC_pic_test/Manhattan_Mid_Span_West_facing/Images'\n",
    "video_name = '~/NYC_pic_test/Manhattan_Mid_Span_West_facing/Video/my_video.mp4'\n",
    "\n",
    "\n",
    "# Get a list of all JPG files in the specified folder\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "\n",
    "# Read the first image to get its dimensions\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# Create a VideoWriter object to save the video\n",
    "video = cv2.VideoWriter(video_name, 0, 1, (width, height))\n",
    "\n",
    "# Write each image to the video\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "# Release the video writer\n",
    "video.release()\n",
    "\n",
    "\n",
    "s = video_name\n",
    "# Find the last occurrence of '/'\n",
    "last_slash_index = s.rfind('/')\n",
    "\n",
    "# Slice the string to get everything after the last '/'\n",
    "result = s[last_slash_index+1:]\n",
    "location = s[ :last_slash_index]\n",
    "\n",
    "\n",
    "#prints the name of the video if the script works as it should\n",
    "print(f\"Video saved as {result}\")\n",
    "\n",
    "#use if need to print save location of video\n",
    "#print(f\"Video saved at {location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de04bfa-c955-45e4-b904-1b9a32209afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Capture video from file\n",
    "cap = cv2.VideoCapture('~/NYC_pic_test/Manhattan_Mid_Span_West_facing/Video/my_video.mp4')\n",
    "\n",
    "# Minimum rectangle width and height\n",
    "min_width_react=80\n",
    "min_hieght_react=80\n",
    "\n",
    "# Line position for counting\n",
    "count_line_postion = 550\n",
    "\n",
    "# Initialize Substructor\n",
    "algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "def center_handle(x,y,w,h):\n",
    "    x1 = int(w/2)\n",
    "    y1 = int(h/2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "\n",
    "detect = []\n",
    "\n",
    "# Infinite loop to process video frames\n",
    "while True:\n",
    "    ret,frame1=cap.read()\n",
    "    grey = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey,(3,3),5)\n",
    "    #applying on each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub,np.ones((5,5)))\n",
    "    kernal = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,())\n",
    "    dilatada = cv2.morphologyEX(dilat, cv2.MORPH_CLOSE, kernal)\n",
    "    dilatada = cv2.morphologyEX(dilatada, cv2.MORPH_CLOSE, kernal)\n",
    "    counterShape = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    h = counterShape\n",
    "\n",
    "    # Draw a line where the counting takes place\n",
    "    cv2.line(frame1,(25,count_line_position),(1200,count_line_position),(255,127,0),3)\n",
    "\n",
    "    # Loop over each contour found\n",
    "    for (i,c) in enumerate(counterShape):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)   # Get bounding box for each contour\n",
    "        validate_counter = (w >= min_width_react) and (h >= min_hieght_react)  # Validate contour by size\n",
    "        if not validate_counter:\n",
    "            continue # Skip small contours\n",
    "\n",
    "        # Draw rectangle around valid contours\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "         # Calculate center of the contour and add to detect list\n",
    "        center = center_handle(w,y,w,h)\n",
    "        detect.append(center)\n",
    "        \n",
    "        # Draw center of the contour\n",
    "        cv2.circle(frame1,center,4, (0,0,255),-1)\n",
    "\n",
    "\n",
    "        for (x,y) in detect:\n",
    "            if x < (count_line_postion + offset) and y < (count_line_postion + offset):\n",
    "                counter += 1\n",
    "            cv2.line(frame1,(25,count_line_postion),(1200,count_line_postion),(0,127,255),3)\n",
    "            detect.remove(x,y)\n",
    "            \n",
    "            print(\"Vehicle Counter:\" + str(counter))\n",
    "\n",
    "    # Display vehicle count on the frame\n",
    "    cv2.putText(frame1,\"VEHICLE COUNTER :\" + str(counter),(450,70),cv2.FONT_HERSHEY_SIMPLEX)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Original', frame1)\n",
    "\n",
    "    # Break the loop when 'Enter' key is pressed\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "# Clean up: close all windows and release video capture object\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d543781-376c-415f-b83f-b660681b9e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
